[model]
type = "seqdistmodel"
package = "models.mamba"

[scaling]
strategy = "pa"

[standardisation]
standardise = 1
mean = 93.69239463939118
stdev = 23.506745239082388

[run_info]
sample_type = "dna"
sample_rate = 5000

[qscore]
scale = 1.05
bias = 1.3

[basecaller]
batchsize = 128
chunksize = 5000
overlap = 100

[training]
command = "train"
training_directory = "./model_dir/model_optuna_512_3/"
config = "models/config/mamba.toml"
pretrained = ""
directory = "PosixPath('squigulator/fast5/training/example_data_dna_r10.4.1_v0')"
device = "cuda"
lr = "5e-4"
seed = 25
epochs = 2
batch = 64
chunks = 20000
valid_chunks = 2000
no_amp = false
force = true
restore_optim = false
nondeterministic = false
save_optim_every = 10
grad_accum_split = 2
quantile_grad_clip = true
num_workers = 4
optuna = true
func = "<function main at 0x7f885e7eb490>"

[model.seqdist]
state_len = 5
alphabet = [ "N", "A", "C", "G", "T",]

[model.encoder]
type = "namedserial"

[model.encoder.conv]
type = "serial"
[[model.encoder.conv.sublayers]]
type = "convolution"
insize = 1
size = 64
bias = true
winlen = 5
stride = 1
padding = 2
activation = "swish"
norm = "batchnorm"

[[model.encoder.conv.sublayers]]
type = "convolution"
insize = 64
size = 64
bias = true
winlen = 5
stride = 1
padding = 2
activation = "swish"
norm = "batchnorm"

[[model.encoder.conv.sublayers]]
type = "convolution"
insize = 64
size = 128
bias = true
winlen = 9
stride = 3
padding = 4
activation = "swish"
norm = "batchnorm"

[[model.encoder.conv.sublayers]]
type = "convolution"
insize = 128
size = 128
bias = true
winlen = 9
stride = 2
padding = 4
activation = "swish"
norm = "batchnorm"

[[model.encoder.conv.sublayers]]
type = "convolution"
insize = 128
size = 256
bias = true
winlen = 5
stride = 2
padding = 2
activation = "swish"
norm = "batchnorm"

[[model.encoder.conv.sublayers]]
type = "convolution"
insize = 256
size = 512
bias = true
winlen = 5
stride = 2
padding = 2
activation = "swish"
norm = "batchnorm"

[[model.encoder.conv.sublayers]]
type = "convolution"
insize = 512
size = 512
bias = true
winlen = 5
stride = 2
padding = 2
activation = "swish"
norm = "batchnorm"

[[model.encoder.conv.sublayers]]
type = "convolution"
insize = 512
size = 1024
bias = true
winlen = 5
stride = 2
padding = 2
activation = "swish"
norm = "batchnorm"

[[model.encoder.conv.sublayers]]
type = "convolution"
insize = 1024
size = 1024
bias = true
winlen = 5
stride = 2
padding = 2
activation = "swish"
norm = "batchnorm"

[[model.encoder.conv.sublayers]]
type = "permute"
dims = [ 0, 2, 1,]

[model.encoder.transformer_encoder]
type = "stack"
depth = 1

[model.encoder.upsample]
type = "linearupsample"
d_model = 1024
scale_factor = 2

[model.encoder.crf]
type = "linearcrfencoder"
insize = 1024
n_base = 4
state_len = 5
bias = false
scale = 5.0
blank_score = 2.0
expand_blanks = true
permute = [ 1, 0, 2,]

[model.encoder.transformer_encoder.layer]
type = "mamba2layer"
d_model = 1024
nhead = 4
d_state = 64
headdim = 256
d_conv = 4
nlayer = 1
chunk_size = 512
dim_feedforward = 2048
deepnorm_alpha = 2.4494897
deepnorm_beta = 0.2886751

